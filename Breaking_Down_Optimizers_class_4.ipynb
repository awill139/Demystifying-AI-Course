{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breaking Down Optimizers - class 4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awill139/Demystifying-AI-Course/blob/master/Breaking_Down_Optimizers_class_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7YpTORXOw6g",
        "colab_type": "text"
      },
      "source": [
        "In class 4, we will break down optimizers a little better than last time, and then compare all of our work to what can be done in Tensorflow 2.0 (Keras)\n",
        "\n",
        "We will use one of the most famous machine learning datasets, MNIST which is recognition of handwritten digits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKiHGDmMnnHH",
        "colab_type": "code",
        "outputId": "6a8beee8-2fee-4d41-dc26-2704c4117fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.datasets\n",
        "import math\n",
        "!pip install tensorflow==2.0.0-alpha0\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0-alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/39/f99185d39131b8333afcfe1dcdb0629c2ffc4ecfb0e4c14ca210d620e56c/tensorflow-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (79.9MB)\n",
            "\u001b[K     |████████████████████████████████| 79.9MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.33.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.0.7)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.12.0)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 36.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.16.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.1.0)\n",
            "Collecting google-pasta>=0.1.2 (from tensorflow==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/68/a14620bfb042691f532dcde8576ff82ee82e4c003cdc0a3dbee5f289cee6/google_pasta-0.1.6-py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 26.5MB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 45.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (3.7.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.0.9)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-alpha0) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (0.15.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-alpha0) (41.0.1)\n",
            "Installing collected packages: tb-nightly, google-pasta, tf-estimator-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 1.13.1\n",
            "    Uninstalling tensorflow-1.13.1:\n",
            "      Successfully uninstalled tensorflow-1.13.1\n",
            "Successfully installed google-pasta-0.1.6 tb-nightly-1.14.0a20190301 tensorflow-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irPvgVg3PRwT",
        "colab_type": "text"
      },
      "source": [
        "Start by loading the data and processesing it\n",
        "\n",
        "We need to break down the pictures of the digits into single arrays of 784 as opposed to the original 28 x 28 and scale it down so each value is between 1 and 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEHhU2EReyBf",
        "colab_type": "code",
        "outputId": "f95f4a15-59ce-41ca-e350-5fddab70b991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x = x_train.reshape(60000, 784).T\n",
        "x_test = x_test.reshape(10000, 784).T\n",
        "y = y_train.reshape(1, y_train.shape[0])\n",
        "y_new = np.eye(10)[y.astype('int32')]\n",
        "y_new = y_new.T.reshape(10, 60000)\n",
        "\n",
        "y_test = y_test.reshape(1, y_test.shape[0])\n",
        "y_test = np.eye(10)[y_test.astype('int32')]\n",
        "y_test = y_test.T.reshape(10, 10000)\n",
        "\n",
        "np.random.seed(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYH4Qeq5Pmr8",
        "colab_type": "text"
      },
      "source": [
        "To show one of our digits and its label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RTzL2p3T2SV",
        "colab_type": "code",
        "outputId": "0849b096-a97f-46d5-a0c0-279cac1fc91f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "i = 1313\n",
        "plt.imshow(x[:,i].reshape(28,28), cmap = matplotlib.cm.binary)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "print(y_new[:,i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsUMIsUOI/wGGIhDIUYc4LQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9FJp969P9Je",
        "colab_type": "text"
      },
      "source": [
        "Some activation functions\n",
        "\n",
        "We will use the softmax activation function which is good for multi-class classification \n",
        "\n",
        "![](https://jamesmccaffrey.files.wordpress.com/2016/03/softmaxequation.jpg?w=640)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4FYRGxyn2RP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "    s = 1/(1+np.exp(-x))\n",
        "    return s\n",
        "\n",
        "def relu(x):\n",
        "    s = np.maximum(0,x)   \n",
        "    return s\n",
        "  \n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBuO-47NQDDa",
        "colab_type": "text"
      },
      "source": [
        "This is the cost function we will use to evaluate softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjpOp136tSrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cost(A2, y):\n",
        "\n",
        "    loss_sum = np.sum(np.multiply(y, np.log(A2)))\n",
        "    m = y.shape[1]\n",
        "    cost = -(1 / m) * loss_sum\n",
        "\n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et05X9XMQKHV",
        "colab_type": "text"
      },
      "source": [
        "We should be familiar with these next parts.\n",
        "\n",
        "We are starting with our normal gradient descent which we have used since the beginning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OpWKgNfoWCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_n = x.shape[0]\n",
        "y_n = y.shape[0]\n",
        "n = x.shape[1]\n",
        "hidden = 128\n",
        "lr = 1.2\n",
        "iters = 101\n",
        "epsilon = 1e-8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaXwopuyn2jb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W1 = np.random.randn(hidden, x_n)\n",
        "b1 = np.zeros(shape=(hidden, 1))\n",
        "W2 = np.random.randn(10, hidden)\n",
        "b2 = np.zeros(shape=(10, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbIIMURroSWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Z1 = np.dot(W1, x) + b1\n",
        "A1 = sigmoid(Z1)\n",
        "Z2 = np.dot(W2, A1) + b2\n",
        "A2 = softmax(Z2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTz3T2p0pP0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dZ2 = A2 - y_new\n",
        "dW2 = (1 / n) * np.dot(dZ2, A1.T)\n",
        "db2 = (1 / n) * np.sum(dZ2, axis=1, keepdims=True)\n",
        "dZ1 = np.multiply(np.dot(W2.T, dZ2), sigmoid(Z1) + (1 - sigmoid(Z1)))\n",
        "dW1 = (1 / n) * np.dot(dZ1, x.T)\n",
        "db1 = (1 / n) * np.sum(dZ1, axis=1, keepdims=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG_T5T4vrvZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W1 = W1 - lr * dW1\n",
        "b1 = b1 - lr * db1\n",
        "W2 = W2 - lr * dW2\n",
        "b2 = b2 - lr * db2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9VedFZ4sSoq",
        "colab_type": "code",
        "outputId": "4a9ff264-d979-4e32-99c4-2ccb9a8e63c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "print('W1: {}'.format(W1))\n",
        "#print('b1: {}'.format(b1))\n",
        "print('W2: {}'.format(W2))\n",
        "#print('b2: {}'.format(b2))\n",
        "print('Cost: {}'.format(compute_cost(A2, y)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1: [[ 1.78862847  0.43650985  0.09649747 ...  2.31777471  0.26024073\n",
            "  -0.01069513]\n",
            " [-0.2319775  -0.11520507 -0.27226691 ... -0.26004721  0.58534487\n",
            "   0.3374218 ]\n",
            " [ 1.3154336  -1.70111231  1.19354402 ... -0.51744219 -1.29282333\n",
            "  -0.2998427 ]\n",
            " ...\n",
            " [ 0.43690314 -1.07846802 -0.49963477 ...  0.44655418 -0.88954612\n",
            "  -2.31765113]\n",
            " [ 1.29223593 -1.22698503 -2.06729195 ...  1.97019621  0.36592614\n",
            "  -2.0289277 ]\n",
            " [-1.13589945  0.33355368  0.61694476 ... -0.69336508 -0.25056634\n",
            "  -0.85917367]]\n",
            "W2: [[-0.78328702  0.00591215 -0.86628507 ...  1.82357535  0.08512974\n",
            "  -0.01082282]\n",
            " [ 0.31786464 -1.36516115 -0.79506735 ...  0.38013504 -0.60144085\n",
            "   0.09036441]\n",
            " [-0.51521194  1.05638074  0.86057146 ... -1.18328979 -0.66520765\n",
            "   0.29526019]\n",
            " ...\n",
            " [-0.16154249 -0.72621059  1.14796735 ...  1.48662007  0.92979232\n",
            "  -0.75490721]\n",
            " [ 2.89923983  0.53437015 -0.32688387 ... -0.31282679 -1.3937242\n",
            "  -0.29258665]\n",
            " [ 1.37515557  1.17648598 -0.71140068 ... -0.20163445  0.60622763\n",
            "   0.35396685]]\n",
            "Cost: 510.1402665040598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G8F6E0Du35D",
        "colab_type": "code",
        "outputId": "fc50ad53-18ff-4dd5-f7cb-9c8fc211ab34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "for i in range(iters):\n",
        "  Z1 = np.dot(W1, x) + b1\n",
        "  A1 = sigmoid(Z1)\n",
        "  Z2 = np.dot(W2, A1) + b2\n",
        "  A2 = softmax(Z2)\n",
        "  \n",
        "  dZ2 = A2 - y_new\n",
        "  dW2 = (1 / n) * np.dot(dZ2, A1.T)\n",
        "  db2 = (1 / n) * np.sum(dZ2, axis=1, keepdims=True)\n",
        "  dZ1 = np.multiply(np.dot(W2.T, dZ2), sigmoid(Z1) + (1 - sigmoid(Z1)))\n",
        "  dW1 = (1 / n) * np.dot(dZ1, x.T)\n",
        "  db1 = (1 / n) * np.sum(dZ1, axis=1, keepdims=True)\n",
        "  \n",
        "  W1 = W1 - lr * dW1\n",
        "  b1 = b1 - lr * db1\n",
        "  W2 = W2 - lr * dW2\n",
        "  b2 = b2 - lr * db2\n",
        "  \n",
        "  if i % 10 == 0:\n",
        "    print('Cost after {} iters: {}'.format(i, compute_cost(A2, y)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after 0 iters: 905.1033892227925\n",
            "Cost after 10 iters: 190.58536806086954\n",
            "Cost after 20 iters: 289.8891146114625\n",
            "Cost after 30 iters: 340.9742984553123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5537b3495fd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mdb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mdZ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdZ2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mdW1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mdb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsSVt8-hQcL7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnjf-PxPwPdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Z1 = np.dot(W1, x_test) + b1\n",
        "A1 = sigmoid(Z1)\n",
        "Z2 = np.dot(W2, A1) + b2\n",
        "A2 = sigmoid(Z2)\n",
        "\n",
        "predictions = np.argmax(A2, axis=0)\n",
        "labels = np.argmax(y_test, axis=0)\n",
        "\n",
        "print(confusion_matrix(predictions, labels))\n",
        "print(classification_report(predictions, labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DM7dhT2QlzC",
        "colab_type": "text"
      },
      "source": [
        "What did one of the results look like?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OZOPLfyeK2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(A2[0])\n",
        "print(y_new[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFqbQWl8QqlH",
        "colab_type": "text"
      },
      "source": [
        "Now, let us try this out with momentum.\n",
        "\n",
        "If you recall, momentum is the when we find the moving average of the past gradients. The hyper parameter beta (sometimes called the decay) essentially controls how many of the past values we want to include. With a beta of 0.9, it is about 10\n",
        "\n",
        "We initialize to 0 to start to have the moment estimates biased toward 0, especially to start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V94Q7yeDpods",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beta = 0.9\n",
        "\n",
        "vW1 = np.zeros_like(W1)\n",
        "vb1 = np.zeros_like(b1)\n",
        "vW2 = np.zeros_like(W2)\n",
        "vb2 = np.zeros_like(b2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT6lQqBRskNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W1 = np.random.randn(hidden, x_n)\n",
        "b1 = np.zeros(shape=(hidden, 1))\n",
        "W2 = np.random.randn(10, hidden)\n",
        "b2 = np.zeros(shape=(10, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3csj3trss7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Z1 = np.dot(W1, x) + b1\n",
        "A1 = sigmoid(Z1)\n",
        "Z2 = np.dot(W2, A1) + b2\n",
        "A2 = softmax(Z2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uHcD1J9sts0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dZ2 = A2 - y_new\n",
        "dW2 = (1 / n) * np.dot(dZ2, A1.T)\n",
        "db2 = (1 / n) * np.sum(dZ2, axis=1, keepdims=True)\n",
        "dZ1 = np.multiply(np.dot(W2.T, dZ2), sigmoid(Z1) + (1 - sigmoid(Z1)))\n",
        "dW1 = (1 / n) * np.dot(dZ1, x.T)\n",
        "db1 = (1 / n) * np.sum(dZ1, axis=1, keepdims=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIy-60OsRQyX",
        "colab_type": "text"
      },
      "source": [
        "We will define the velocity, where momentum really happens. We start by multiplying the beta with the previous velocity, then taking 1 - beta multiplied by the gradient. This is our moving average"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PYSif6_rc1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vW1 = beta * vW1 + (1 - beta) * dW1\n",
        "vb1 = beta * vb1 + (1 - beta) * db1\n",
        "vW2 = beta * vW2 + (1 - beta) * dW2\n",
        "vb2 = beta * vb2 + (1 - beta) * db2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK9IoXj6rn68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W1 = W1 - lr * vW1\n",
        "b1 = b1 - lr * vb1\n",
        "W2 = W2 - lr * vW2\n",
        "b2 = b2 - lr * vb2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9VFbTg6s1yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('W1: {}'.format(W1))\n",
        "#print('b1: {}'.format(b1))\n",
        "print('W2: {}'.format(W2))\n",
        "#print('b2: {}'.format(b2))\n",
        "print('Cost: {}'.format(compute_cost(A2, y)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHJKvxCitDNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vW1 = np.zeros_like(W1)\n",
        "vb1 = np.zeros_like(b1)\n",
        "vW2 = np.zeros_like(W2)\n",
        "vb2 = np.zeros_like(b2)\n",
        "\n",
        "for i in range(iters):\n",
        "  Z1 = np.dot(W1, x) + b1\n",
        "  A1 = sigmoid(Z1)\n",
        "  Z2 = np.dot(W2, A1) + b2\n",
        "  A2 = softmax(Z2)\n",
        "  \n",
        "  dZ2 = A2 - y_new\n",
        "  dW2 = (1 / n) * np.dot(dZ2, A1.T)\n",
        "  db2 = (1 / n) * np.sum(dZ2, axis=1, keepdims=True)\n",
        "  dZ1 = np.multiply(np.dot(W2.T, dZ2), sigmoid(Z1) + (1 - sigmoid(Z1)))\n",
        "  dW1 = (1 / n) * np.dot(dZ1, x.T)\n",
        "  db1 = (1 / n) * np.sum(dZ1, axis=1, keepdims=True)\n",
        "  \n",
        "  vW1 = beta * vW1 + (1 - beta) * dW1\n",
        "  vb1 = beta * vb1 + (1 - beta) * db1\n",
        "  vW2 = beta * vW2 + (1 - beta) * dW2\n",
        "  vb2 = beta * vb2 + (1 - beta) * db2\n",
        "  \n",
        "  W1 = W1 - lr * vW1\n",
        "  b1 = b1 - lr * vb1\n",
        "  W2 = W2 - lr * vW2\n",
        "  b2 = b2 - lr * vb2\n",
        "  \n",
        "  if i % 10 == 0:\n",
        "    print('Cost after {} iters: {}'.format(i, compute_cost(A2, y)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFKJk7lIocic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Z1 = np.dot(W1, x_test) + b1\n",
        "A1 = sigmoid(Z1)\n",
        "Z2 = np.dot(W2, A1) + b2\n",
        "A2 = sigmoid(Z2)\n",
        "\n",
        "predictions = np.argmax(A2, axis=0)\n",
        "labels = np.argmax(y_test, axis=0)\n",
        "\n",
        "print(confusion_matrix(predictions, labels))\n",
        "print(classification_report(predictions, labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yJwEl24Sd9O",
        "colab_type": "text"
      },
      "source": [
        "Now we try with RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU7ynvNYuRV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W1 = np.random.randn(hidden, x_n)\n",
        "b1 = np.zeros(shape=(hidden, 1))\n",
        "W2 = np.random.randn(10, hidden)\n",
        "b2 = np.zeros(shape=(10, 1))\n",
        "\n",
        "Z1 = np.dot(W1, x) + b1\n",
        "A1 = sigmoid(Z1)\n",
        "Z2 = np.dot(W2, A1) + b2\n",
        "A2 = softmax(Z2)\n",
        "\n",
        "dZ2 = A2 - y_new\n",
        "dW2 = (1 / n) * np.dot(dZ2, A1.T)\n",
        "db2 = (1 / n) * np.sum(dZ2, axis=1, keepdims=True)\n",
        "dZ1 = np.multiply(np.dot(W2.T, dZ2), sigmoid(Z1) + (1 - sigmoid(Z1)))\n",
        "dW1 = (1 / n) * np.dot(dZ1, x.T)\n",
        "db1 = (1 / n) * np.sum(dZ1, axis=1, keepdims=True)\n",
        "print('W1: {}'.format(W1))\n",
        "print('b1: {}'.format(b1))\n",
        "print('W2: {}'.format(W2))\n",
        "print('b2: {}'.format(b2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDjfly1CShlA",
        "colab_type": "text"
      },
      "source": [
        "Similar to momentum, we start with initializing to zero so we have no bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDmkFiMBFajD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sW1 = np.zeros_like(W1)\n",
        "sb1 = np.zeros_like(b1)\n",
        "sW2 = np.zeros_like(W2)\n",
        "sb2 = np.zeros_like(b2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KrzWcNrSmwj",
        "colab_type": "text"
      },
      "source": [
        "This is where we start to deviate. Instead of multiplying our 0.1 (1 - beta) by the derivative directly, we square it first. this is the S part of RMS or root mean square"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SXyeVOPFk8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sW1 = beta * sW1 + (1 - beta) * np.power(dW1, 2)\n",
        "sb1 = beta * sb1 + (1 - beta) * np.power(db1, 2)\n",
        "sW2 = beta * sW2 + (1 - beta) * np.power(dW2, 2)\n",
        "sb2 = beta * sb2 + (1 - beta) * np.power(db2, 2)\n",
        "print('sW1: {}'.format(sW1))\n",
        "print('sb1: {}'.format(sb1))\n",
        "print('sW2: {}'.format(sW2))\n",
        "print('sb2: {}'.format(sb2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovs6X935TCDx",
        "colab_type": "text"
      },
      "source": [
        "Updating the weights is a bit different as well. We take the square root of S added to the hyper parameter epsilon (very small, only there so we do not divide by 0) and then dividing the derivative will give us the average or mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxdJ2qD9F4Or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W1 = W1 - (lr * dW1 / np.sqrt(sW1 + epsilon))\n",
        "b1 = b1 - (lr * db1 / np.sqrt(sb1 + epsilon))\n",
        "W2 = W2 - (lr * dW2 / np.sqrt(sW2 + epsilon))\n",
        "b2 = b2 - (lr * db2 / np.sqrt(sb2 + epsilon))\n",
        "print('W1: {}'.format(W1))\n",
        "print('b1: {}'.format(b1))\n",
        "print('W2: {}'.format(W2))\n",
        "print('b2: {}'.format(b2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux-PWLudJJof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sW1 = np.zeros_like(W1)\n",
        "sb1 = np.zeros_like(b1)\n",
        "sW2 = np.zeros_like(W2)\n",
        "sb2 = np.zeros_like(b2)\n",
        "\n",
        "for i in range(iters):\n",
        "  Z1 = np.dot(W1, x) + b1\n",
        "  A1 = sigmoid(Z1)\n",
        "  Z2 = np.dot(W2, A1) + b2\n",
        "  A2 = softmax(Z2)\n",
        "  \n",
        "  dZ2 = A2 - y_new\n",
        "  dW2 = (1 / n) * np.dot(dZ2, A1.T)\n",
        "  db2 = (1 / n) * np.sum(dZ2, axis=1, keepdims=True)\n",
        "  dZ1 = np.multiply(np.dot(W2.T, dZ2), sigmoid(Z1) + (1 - sigmoid(Z1)))\n",
        "  dW1 = (1 / n) * np.dot(dZ1, x.T)\n",
        "  db1 = (1 / n) * np.sum(dZ1, axis=1, keepdims=True)\n",
        "\n",
        "  sW1 = beta * sW1 + (1 - beta) * np.power(dW1, 2)\n",
        "  sb1 = beta * sb1 + (1 - beta) * np.power(db1, 2)\n",
        "  sW2 = beta * sW2 + (1 - beta) * np.power(dW2, 2)\n",
        "  sb2 = beta * sb2 + (1 - beta) * np.power(db2, 2)\n",
        "\n",
        "  W1 = W1 - (lr * dW1 / np.sqrt(sW1 + epsilon))\n",
        "  b1 = b1 - (lr * db1 / np.sqrt(sb1 + epsilon))\n",
        "  W2 = W2 - (lr * dW2 / np.sqrt(sW2 + epsilon))\n",
        "  b2 = b2 - (lr * db2 / np.sqrt(sb2 + epsilon))\n",
        "\n",
        "  if i % 10 == 0:\n",
        "    print('Cost after {} iters: {}'.format(i, compute_cost(A2, y)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1AxsXNlor8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Z1 = np.dot(W1, x_test) + b1\n",
        "A1 = sigmoid(Z1)\n",
        "Z2 = np.dot(W2, A1) + b2\n",
        "A2 = sigmoid(Z2)\n",
        "\n",
        "predictions = np.argmax(A2, axis=0)\n",
        "labels = np.argmax(y_test, axis=0)\n",
        "\n",
        "print(confusion_matrix(predictions, labels))\n",
        "print(classification_report(predictions, labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRZZO9dPUEJf",
        "colab_type": "text"
      },
      "source": [
        "Now we combine both in Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oGXVqg39Y_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W1 = np.random.randn(hidden, x_n)\n",
        "b1 = np.zeros(shape=(hidden, 1))\n",
        "W2 = np.random.randn(10, hidden)\n",
        "b2 = np.zeros(shape=(10, 1))\n",
        "\n",
        "Z1 = np.dot(W1, x) + b1\n",
        "A1 = sigmoid(Z1)\n",
        "Z2 = np.dot(W2, A1) + b2\n",
        "A2 = softmax(Z2)\n",
        "\n",
        "dZ2 = A2 - y_new\n",
        "dW2 = (1 / n) * np.dot(dZ2, A1.T)\n",
        "db2 = (1 / n) * np.sum(dZ2, axis=1, keepdims=True)\n",
        "dZ1 = np.multiply(np.dot(W2.T, dZ2), sigmoid(Z1) + (1 - sigmoid(Z1)))\n",
        "dW1 = (1 / n) * np.dot(dZ1, x.T)\n",
        "db1 = (1 / n) * np.sum(dZ1, axis=1, keepdims=True)\n",
        "print('W1: {}'.format(W1))\n",
        "print('b1: {}'.format(b1))\n",
        "print('W2: {}'.format(W2))\n",
        "print('b2: {}'.format(b2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz_keqfZUG5i",
        "colab_type": "text"
      },
      "source": [
        "We need both our v and our s, velocity and squared values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Rwg1pMguTRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vW1 = np.zeros_like(W1)\n",
        "vb1 = np.zeros_like(b1)\n",
        "vW2 = np.zeros_like(W2)\n",
        "vb2 = np.zeros_like(b2)\n",
        "sW1 = np.zeros_like(W1)\n",
        "sb1 = np.zeros_like(b1)\n",
        "sW2 = np.zeros_like(W2)\n",
        "sb2 = np.zeros_like(b2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpT4FXtwUPwX",
        "colab_type": "text"
      },
      "source": [
        "Adam has a few extra hyper parameters. Since it combines RMSprop and momentum, each needs its own beta value. These can be the same, but it has been found that 0.9 and 0.999 work best. We also have the epsilon where, even though it is a hyper parameter it is only there so we do not divide by 0 so tuning it isn't needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aIVcPrK7X8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beta1 = 0.9\n",
        "beta2 = 0.999\n",
        "epsilon = 1e-8\n",
        "t = 1 #Not a hyper parameter, a counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh1wa1EdUN7A",
        "colab_type": "text"
      },
      "source": [
        "This is the same as velocity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mISsQZQb6HCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vW1 = beta1 * vW1 + (1 - beta1) * dW1\n",
        "vb1 = beta1 * vb1 + (1 - beta) * db1\n",
        "vW2 = beta1 * vW2 + (1 - beta) * dW2\n",
        "vb2 = beta1 * vb2 + (1 - beta) * db2\n",
        "\n",
        "print('vW1: {}'.format(vW1))\n",
        "print('vb1: {}'.format(vb1))\n",
        "print('vW2: {}'.format(vW2))\n",
        "print('vb2: {}'.format(vb2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H61cbULlUd5o",
        "colab_type": "text"
      },
      "source": [
        "This is where Adam takes a step further. In momentum and rmsprop, we run the risk of having small velocities and S's\n",
        "\n",
        "The corrected value will bring the velocity back closer to 1. If they are defined as 0 at first but they should be much larger, this will correct that problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTDjkIwL7kbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vW1_corrected = vW1 / (1 - np.power(beta1, t))\n",
        "vb1_corrected = vb1 / (1 - np.power(beta1, t))\n",
        "vW2_corrected = vW2 / (1 - np.power(beta1, t))\n",
        "vb2_corrected = vb2 / (1 - np.power(beta1, t))\n",
        "\n",
        "print('W1: {}'.format(vW1_corrected))\n",
        "print('b1: {}'.format(vb1_corrected))\n",
        "print('W2: {}'.format(vW2_corrected))\n",
        "print('b2: {}'.format(vb2_corrected))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN6t02qGV-he",
        "colab_type": "text"
      },
      "source": [
        "Same as RMSprop except it is using beta2 (0.999) instead of beta (0.9)\n",
        "\n",
        "This is just what the authors of the paper found to be the most effective but as a hyper parameter, you may tune it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN3WxJoJ7oBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sW1 = beta2 * sW1 + (1 - beta2) * np.power(dW1, 2)\n",
        "sb1 = beta2 * sb1 + (1 - beta2) * np.power(db1, 2)\n",
        "sW2 = beta2 * sW2 + (1 - beta2) * np.power(dW2, 2)\n",
        "sb2 = beta2 * sb2 + (1 - beta2) * np.power(db2, 2)\n",
        "\n",
        "print('sW1: {}'.format(sW1))\n",
        "print('sb1: {}'.format(sb1))\n",
        "print('sW2: {}'.format(sW2))\n",
        "print('sb2: {}'.format(sb2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82p7jjfnWR53",
        "colab_type": "text"
      },
      "source": [
        "We need to correct this one as well as it was initialized as 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJTbXtRQ8TuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sW1_corrected = sW1 / (1 - np.power(beta2, t))\n",
        "sb1_corrected = sb1 / (1 - np.power(beta2, t))\n",
        "sW2_corrected = sW2 / (1 - np.power(beta2, t))\n",
        "sb2_corrected = sb2 / (1 - np.power(beta2, t))\n",
        "\n",
        "print('sW1_corrected: {}'.format(sW1_corrected))\n",
        "print('sb1_corrected: {}'.format(sb1_corrected))\n",
        "print('sW2_corrected: {}'.format(sW2_corrected))\n",
        "print('sb2_corrected: {}'.format(sb2_corrected))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II96xZFUWXhg",
        "colab_type": "text"
      },
      "source": [
        "And we simply update it in a way that resembles both momentum and RMS prop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMtj_ty18cOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W1 = W1 - lr * vW1_corrected / np.sqrt(sW1_corrected + epsilon)\n",
        "b1 = b1 - lr * vb1_corrected / np.sqrt(sb1_corrected + epsilon)\n",
        "W2 = W2 - lr * vW2_corrected / np.sqrt(sW2_corrected + epsilon)\n",
        "b2 = b2 - lr * vb2_corrected / np.sqrt(sb2_corrected + epsilon)\n",
        "\n",
        "print('W1: {}'.format(W1))\n",
        "print('b1: {}'.format(b1))\n",
        "print('W2: {}'.format(W2))\n",
        "print('b2: {}'.format(b2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI2065A89Tsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vW1 = np.zeros_like(W1)\n",
        "vb1 = np.zeros_like(b1)\n",
        "vW2 = np.zeros_like(W2)\n",
        "vb2 = np.zeros_like(b2)\n",
        "sW1 = np.zeros_like(W1)\n",
        "sb1 = np.zeros_like(b1)\n",
        "sW2 = np.zeros_like(W2)\n",
        "sb2 = np.zeros_like(b2)\n",
        "\n",
        "for i in range(iters):\n",
        "  t += 1\n",
        "  Z1 = np.dot(W1, x) + b1\n",
        "  A1 = sigmoid(Z1)\n",
        "  Z2 = np.dot(W2, A1) + b2\n",
        "  A2 = softmax(Z2)\n",
        "  \n",
        "  dZ2 = A2 - y_new\n",
        "  dW2 = (1 / n) * np.dot(dZ2, A1.T)\n",
        "  db2 = (1 / n) * np.sum(dZ2, axis=1, keepdims=True)\n",
        "  dZ1 = np.multiply(np.dot(W2.T, dZ2), sigmoid(Z1) + (1 - sigmoid(Z1)))\n",
        "  dW1 = (1 / n) * np.dot(dZ1, x.T)\n",
        "  db1 = (1 / n) * np.sum(dZ1, axis=1, keepdims=True)\n",
        "  \n",
        "  vW1 = beta1 * vW1 + (1 - beta1) * dW1\n",
        "  vb1 = beta1 * vb1 + (1 - beta) * db1\n",
        "  vW2 = beta1 * vW2 + (1 - beta) * dW2\n",
        "  vb2 = beta1 * vb2 + (1 - beta) * db2\n",
        "\n",
        "  vW1_corrected = vW1 / (1 - np.power(beta1, t))\n",
        "  vb1_corrected = vb1 / (1 - np.power(beta1, t))\n",
        "  vW2_corrected = vW2 / (1 - np.power(beta1, t))\n",
        "  vb2_corrected = vb2 / (1 - np.power(beta1, t))\n",
        "\n",
        "  sW1 = beta2 * sW1 + (1 - beta2) * np.power(dW1, 2)\n",
        "  sb1 = beta2 * sb1 + (1 - beta2) * np.power(db1, 2)\n",
        "  sW2 = beta2 * sW2 + (1 - beta2) * np.power(dW2, 2)\n",
        "  sb2 = beta2 * sb2 + (1 - beta2) * np.power(db2, 2)\n",
        "\n",
        "  sW1_corrected = sW1 / (1 - np.power(beta2, t))\n",
        "  sb1_corrected = sb1 / (1 - np.power(beta2, t))\n",
        "  sW2_corrected = sW2 / (1 - np.power(beta2, t))\n",
        "  sb2_corrected = sb2 / (1 - np.power(beta2, t))\n",
        "\n",
        "  W1 = W1 - lr * vW1_corrected / np.sqrt(sW1_corrected + epsilon)\n",
        "  b1 = b1 - lr * vb1_corrected / np.sqrt(sb1_corrected + epsilon)\n",
        "  W2 = W2 - lr * vW2_corrected / np.sqrt(sW2_corrected + epsilon)\n",
        "  b2 = b2 - lr * vb2_corrected / np.sqrt(sb2_corrected + epsilon)\n",
        "  \n",
        "  if i % 10 == 0:\n",
        "    print('Cost after {} iters: {}'.format(i, compute_cost(A2, y)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qvts5t5o24N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Z1 = np.dot(W1, x_test) + b1\n",
        "A1 = sigmoid(Z1)\n",
        "Z2 = np.dot(W2, A1) + b2\n",
        "A2 = sigmoid(Z2)\n",
        "\n",
        "predictions = np.argmax(A2, axis=0)\n",
        "labels = np.argmax(y_test, axis=0)\n",
        "\n",
        "print(confusion_matrix(predictions, labels))\n",
        "print(classification_report(predictions, labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzSQOFKCWipT",
        "colab_type": "text"
      },
      "source": [
        "This was all fun, but let's try it in a modern day framework"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ICnHxV2B724",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-zgWPjmWnAn",
        "colab_type": "text"
      },
      "source": [
        "First with SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9GbKLDQK559",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='sigmoid'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='SGD',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8EZI0GqK7Nl",
        "colab_type": "code",
        "outputId": "8991c2af-469b-47de-cdd4-021cf5957eb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 4s 62us/sample - loss: 2.2017 - accuracy: 0.3112\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 1.9580 - accuracy: 0.6161\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 1.7509 - accuracy: 0.7020\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 1.5632 - accuracy: 0.7394\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 62us/sample - loss: 1.3985 - accuracy: 0.7653\n",
            "10000/10000 [==============================] - 0s 42us/sample - loss: 1.3078 - accuracy: 0.7829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3078300415039064, 0.7829]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQPPPSe_XMcK",
        "colab_type": "text"
      },
      "source": [
        "With momentum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i60OBW2EW17D",
        "colab_type": "code",
        "outputId": "4cf688c8-5308-4067-f724-5bc052a7ac96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='sigmoid'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "withMomentum = tf.keras.optimizers.SGD(momentum=0.9)\n",
        "\n",
        "model.compile(optimizer=withMomentum,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 1.4505 - accuracy: 0.7062\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 0.6979 - accuracy: 0.8496\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.5207 - accuracy: 0.8730\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4463 - accuracy: 0.8848\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4049 - accuracy: 0.8916\n",
            "10000/10000 [==============================] - 0s 38us/sample - loss: 0.3728 - accuracy: 0.9025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.37280383710861204, 0.9025]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Cgcyf4eXOhb",
        "colab_type": "text"
      },
      "source": [
        "RMSProp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1w_-v0pK8jv",
        "colab_type": "code",
        "outputId": "a6835cca-e301-4886-cd98-75a5e4bb65dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='sigmoid'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='RMSProp',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.3726 - accuracy: 0.9017\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1927 - accuracy: 0.9434\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1462 - accuracy: 0.9567\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1189 - accuracy: 0.9653\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1008 - accuracy: 0.9706\n",
            "10000/10000 [==============================] - 0s 41us/sample - loss: 0.1042 - accuracy: 0.9699\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.10415860395301134, 0.9699]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMPL89Q3XPwN",
        "colab_type": "text"
      },
      "source": [
        "Finally, Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BCCT1E04f51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "act = tf.keras.activations.sigmoid(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbE4liUvLPyd",
        "colab_type": "code",
        "outputId": "b230c415-7cac-4d7d-e0ff-77b9801f68aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2532 - accuracy: 0.9277\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1145 - accuracy: 0.9661\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0789 - accuracy: 0.9762\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0583 - accuracy: 0.9819\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0454 - accuracy: 0.9856\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0352 - accuracy: 0.9890\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0281 - accuracy: 0.9914\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0227 - accuracy: 0.9931\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0191 - accuracy: 0.9939\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0154 - accuracy: 0.9952\n",
            "10000/10000 [==============================] - 0s 41us/sample - loss: 0.0874 - accuracy: 0.9753\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08744631985542364, 0.9753]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBQJCEp2eWMJ",
        "colab_type": "text"
      },
      "source": [
        "It is pretty easy to see why people don't make everything by hand. Not only is the exact same code achievable in much fewer lines, it is also optimized to achieve the best results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMk2qdwe8x6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa9TpPEh80ri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA-2CINF82IG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGZt6VF08_3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwkig0WO9BJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6aP1mUK9lA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW3TOD_F9mBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qathZ3MA-oXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}